{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTm5qAfOlZXG6SGZvb+iBz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/assiya-ouarradi/javagamesnake--1-/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8KtpGf-feRN",
        "outputId": "018889c5-382d-4bb4-82a3-d42668177997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the tools we need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "print(\"‚úì All libraries loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn5tXmoof52J",
        "outputId": "f1cde056-76e8-4955-ccbc-a81f12f9295a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì All libraries loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "url = \"https://confrecordings.ams3.digitaloceanspaces.com/bodyPerformance.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Check if it worked\n",
        "print(f\"‚úì Dataset loaded: {len(df)} rows\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klnbT6YVgARb",
        "outputId": "95f5d20c-0630-42b6-a2c8-22e92352b8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Dataset loaded: 13393 rows\n",
            "\n",
            "First 5 rows:\n",
            "    age gender  height_cm  weight_kg  body fat_%  diastolic  systolic  \\\n",
            "0  27.0      M      172.3      75.24        21.3       80.0     130.0   \n",
            "1  25.0      M      165.0      55.80        15.7       77.0     126.0   \n",
            "2  31.0      M      179.6      78.00        20.1       92.0     152.0   \n",
            "3  32.0      M      174.5      71.10        18.4       76.0     147.0   \n",
            "4  28.0      M      173.8      67.70        17.1       70.0     127.0   \n",
            "\n",
            "   gripForce  sit and bend forward_cm  sit-ups counts  broad jump_cm class  \n",
            "0       54.9                     18.4            60.0          217.0     C  \n",
            "1       36.4                     16.3            53.0          229.0     A  \n",
            "2       44.8                     12.0            49.0          181.0     C  \n",
            "3       41.4                     15.2            53.0          219.0     B  \n",
            "4       43.5                     27.1            45.0          217.0     B  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîç Exploring data...\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nColumn types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSaEmP9wgbQa",
        "outputId": "01d28ce5-6922-49ac-a166-827079435468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Exploring data...\n",
            "\n",
            "First 5 rows:\n",
            "    age gender  height_cm  weight_kg  body fat_%  diastolic  systolic  \\\n",
            "0  27.0      M      172.3      75.24        21.3       80.0     130.0   \n",
            "1  25.0      M      165.0      55.80        15.7       77.0     126.0   \n",
            "2  31.0      M      179.6      78.00        20.1       92.0     152.0   \n",
            "3  32.0      M      174.5      71.10        18.4       76.0     147.0   \n",
            "4  28.0      M      173.8      67.70        17.1       70.0     127.0   \n",
            "\n",
            "   gripForce  sit and bend forward_cm  sit-ups counts  broad jump_cm class  \n",
            "0       54.9                     18.4            60.0          217.0     C  \n",
            "1       36.4                     16.3            53.0          229.0     A  \n",
            "2       44.8                     12.0            49.0          181.0     C  \n",
            "3       41.4                     15.2            53.0          219.0     B  \n",
            "4       43.5                     27.1            45.0          217.0     B  \n",
            "\n",
            "Column types:\n",
            "age                        float64\n",
            "gender                      object\n",
            "height_cm                  float64\n",
            "weight_kg                  float64\n",
            "body fat_%                 float64\n",
            "diastolic                  float64\n",
            "systolic                   float64\n",
            "gripForce                  float64\n",
            "sit and bend forward_cm    float64\n",
            "sit-ups counts             float64\n",
            "broad jump_cm              float64\n",
            "class                       object\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "age                        0\n",
            "gender                     0\n",
            "height_cm                  0\n",
            "weight_kg                  0\n",
            "body fat_%                 0\n",
            "diastolic                  0\n",
            "systolic                   0\n",
            "gripForce                  0\n",
            "sit and bend forward_cm    0\n",
            "sit-ups counts             0\n",
            "broad jump_cm              0\n",
            "class                      0\n",
            "dtype: int64\n",
            "\n",
            "Basic statistics:\n",
            "                age     height_cm     weight_kg    body fat_%     diastolic  \\\n",
            "count  13393.000000  13393.000000  13393.000000  13393.000000  13393.000000   \n",
            "mean      36.775106    168.559807     67.447316     23.240165     78.796842   \n",
            "std       13.625639      8.426583     11.949666      7.256844     10.742033   \n",
            "min       21.000000    125.000000     26.300000      3.000000      0.000000   \n",
            "25%       25.000000    162.400000     58.200000     18.000000     71.000000   \n",
            "50%       32.000000    169.200000     67.400000     22.800000     79.000000   \n",
            "75%       48.000000    174.800000     75.300000     28.000000     86.000000   \n",
            "max       64.000000    193.800000    138.100000     78.400000    156.200000   \n",
            "\n",
            "           systolic     gripForce  sit and bend forward_cm  sit-ups counts  \\\n",
            "count  13393.000000  13393.000000             13393.000000    13393.000000   \n",
            "mean     130.234817     36.963877                15.209268       39.771224   \n",
            "std       14.713954     10.624864                 8.456677       14.276698   \n",
            "min        0.000000      0.000000               -25.000000        0.000000   \n",
            "25%      120.000000     27.500000                10.900000       30.000000   \n",
            "50%      130.000000     37.900000                16.200000       41.000000   \n",
            "75%      141.000000     45.200000                20.700000       50.000000   \n",
            "max      201.000000     70.500000               213.000000       80.000000   \n",
            "\n",
            "       broad jump_cm  \n",
            "count   13393.000000  \n",
            "mean      190.129627  \n",
            "std        39.868000  \n",
            "min         0.000000  \n",
            "25%       162.000000  \n",
            "50%       193.000000  \n",
            "75%       221.000000  \n",
            "max       303.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nouvelle section"
      ],
      "metadata": {
        "id": "xvCZ8upbHZ2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nouvelle section"
      ],
      "metadata": {
        "id": "uaddmhB_F0pA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüßπ Cleaning data...\")\n",
        "rows_before = len(df)\n",
        "df = df.dropna()\n",
        "rows_after = len(df)\n",
        "print(f\"‚úì Removed {rows_before - rows_after} rows with missing values\")\n",
        "print(f\"‚úì {rows_after} rows remaining\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJb-yLTRhnAx",
        "outputId": "3b81e48b-0719-4b6b-8f2c-1e869c004940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üßπ Cleaning data...\n",
            "‚úì Removed 0 rows with missing values\n",
            "‚úì 13393 rows remaining\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüî¢ Converting text to numbers...\")\n",
        "\n",
        "# Check what we're converting\n",
        "print(f\"Gender values: {df['gender'].unique()}\")\n",
        "print(f\"Class values: {df['class'].unique()}\")\n",
        "\n",
        "# Convert\n",
        "le_gender = LabelEncoder()\n",
        "le_class = LabelEncoder()\n",
        "\n",
        "df['gender'] = le_gender.fit_transform(df['gender'])\n",
        "df['class'] = le_class.fit_transform(df['class'])\n",
        "\n",
        "print(f\"‚úì Gender encoded: {df['gender'].unique()}\")\n",
        "print(f\"‚úì Class encoded: {df['class'].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zdi7Je9ibof",
        "outputId": "31b2958b-e1c3-4f19-bab4-bd0af86cbaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî¢ Converting text to numbers...\n",
            "Gender values: ['M' 'F']\n",
            "Class values: ['C' 'A' 'B' 'D']\n",
            "‚úì Gender encoded: [1 0]\n",
            "‚úì Class encoded: [2 0 1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n‚úÇÔ∏è Separating features from target...\")\n",
        "\n",
        "# X = everything except 'class'\n",
        "X = df.drop('class', axis=1)\n",
        "\n",
        "# y = only 'class'\n",
        "y = df['class']\n",
        "\n",
        "print(f\"‚úì Features (X): {X.shape}\")\n",
        "print(f\"‚úì Target (y): {y.shape}\")\n",
        "print(f\"‚úì Feature names: {list(X.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wruT5j-3jQKd",
        "outputId": "0ad79895-198b-4658-b918-c1b7324a8903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÇÔ∏è Separating features from target...\n",
            "‚úì Features (X): (13393, 11)\n",
            "‚úì Target (y): (13393,)\n",
            "‚úì Feature names: ['age', 'gender', 'height_cm', 'weight_kg', 'body fat_%', 'diastolic', 'systolic', 'gripForce', 'sit and bend forward_cm', 'sit-ups counts', 'broad jump_cm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìä Splitting into training and testing sets...\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,      # 20% for testing\n",
        "    random_state=42     # for reproducibility\n",
        ")\n",
        "\n",
        "print(f\"‚úì Training samples: {len(X_train)} (80%)\")\n",
        "print(f\"‚úì Testing samples: {len(X_test)} (20%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuI5ZMDMntXy",
        "outputId": "573a5e1d-1d97-4725-b615-0b088bb06127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Splitting into training and testing sets...\n",
            "‚úì Training samples: 10714 (80%)\n",
            "‚úì Testing samples: 2679 (20%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n‚öñÔ∏è Scaling data...\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"‚úì Data normalized\")\n",
        "print(f\"  Before scaling - mean: {X_train.mean().mean():.2f}\")\n",
        "print(f\"  After scaling - mean: {X_train_scaled.mean():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSMrK24howPl",
        "outputId": "eef7bc04-bc38-4413-9bfa-1301963ddbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚öñÔ∏è Scaling data...\n",
            "‚úì Data normalized\n",
            "  Before scaling - mean: 71.59\n",
            "  After scaling - mean: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüß† Building Neural Network...\")\n",
        "\n",
        "mlp_clf = MLPClassifier(\n",
        "    hidden_layer_sizes=(150, 100, 50),  # 3 hidden layers\n",
        "    max_iter=300,                        # 300 training iterations\n",
        "    activation='relu',                   # ReLU activation\n",
        "    solver='adam',                       # Adam optimizer\n",
        "    random_state=42,\n",
        "    verbose=True                         # Show progress\n",
        ")\n",
        "\n",
        "print(\"‚úì Neural Network created!\")\n",
        "print(\"  Architecture: Input ‚Üí 150 ‚Üí 100 ‚Üí 50 ‚Üí Output\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f9NsCGeqRo-",
        "outputId": "586d6efc-065b-402c-8914-b10d00aebc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Building Neural Network...\n",
            "‚úì Neural Network created!\n",
            "  Architecture: Input ‚Üí 150 ‚Üí 100 ‚Üí 50 ‚Üí Output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nüéì Training Neural Network...\")\n",
        "print(\"(This will take 1-2 minutes...)\\n\")\n",
        "\n",
        "mlp_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"\\n‚úì Training completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZeIz-ehsjiU",
        "outputId": "b897c2d9-2cfd-477b-8bd9-f1569c29bce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéì Training Neural Network...\n",
            "(This will take 1-2 minutes...)\n",
            "\n",
            "Iteration 1, loss = 1.07839559\n",
            "Iteration 2, loss = 0.83398280\n",
            "Iteration 3, loss = 0.77265781\n",
            "Iteration 4, loss = 0.73169951\n",
            "Iteration 5, loss = 0.69902810\n",
            "Iteration 6, loss = 0.67861885\n",
            "Iteration 7, loss = 0.65660783\n",
            "Iteration 8, loss = 0.64215653\n",
            "Iteration 9, loss = 0.63401346\n",
            "Iteration 10, loss = 0.63069086\n",
            "Iteration 11, loss = 0.61492384\n",
            "Iteration 12, loss = 0.60839888\n",
            "Iteration 13, loss = 0.60215117\n",
            "Iteration 14, loss = 0.59789535\n",
            "Iteration 15, loss = 0.59142734\n",
            "Iteration 16, loss = 0.58880503\n",
            "Iteration 17, loss = 0.57878833\n",
            "Iteration 18, loss = 0.57329723\n",
            "Iteration 19, loss = 0.56901790\n",
            "Iteration 20, loss = 0.56508083\n",
            "Iteration 21, loss = 0.55940025\n",
            "Iteration 22, loss = 0.56019431\n",
            "Iteration 23, loss = 0.55349117\n",
            "Iteration 24, loss = 0.54954806\n",
            "Iteration 25, loss = 0.54698068\n",
            "Iteration 26, loss = 0.54088197\n",
            "Iteration 27, loss = 0.53696514\n",
            "Iteration 28, loss = 0.53383184\n",
            "Iteration 29, loss = 0.53106979\n",
            "Iteration 30, loss = 0.53473877\n",
            "Iteration 31, loss = 0.52305791\n",
            "Iteration 32, loss = 0.52454665\n",
            "Iteration 33, loss = 0.51801578\n",
            "Iteration 34, loss = 0.51364397\n",
            "Iteration 35, loss = 0.50973087\n",
            "Iteration 36, loss = 0.51072787\n",
            "Iteration 37, loss = 0.50875808\n",
            "Iteration 38, loss = 0.50867229\n",
            "Iteration 39, loss = 0.50133916\n",
            "Iteration 40, loss = 0.49724577\n",
            "Iteration 41, loss = 0.49600430\n",
            "Iteration 42, loss = 0.49320074\n",
            "Iteration 43, loss = 0.49019899\n",
            "Iteration 44, loss = 0.48263726\n",
            "Iteration 45, loss = 0.47871437\n",
            "Iteration 46, loss = 0.47994522\n",
            "Iteration 47, loss = 0.47747688\n",
            "Iteration 48, loss = 0.47272501\n",
            "Iteration 49, loss = 0.47168282\n",
            "Iteration 50, loss = 0.46375234\n",
            "Iteration 51, loss = 0.46651722\n",
            "Iteration 52, loss = 0.46595268\n",
            "Iteration 53, loss = 0.45746553\n",
            "Iteration 54, loss = 0.45636485\n",
            "Iteration 55, loss = 0.45222230\n",
            "Iteration 56, loss = 0.45770011\n",
            "Iteration 57, loss = 0.44805319\n",
            "Iteration 58, loss = 0.44577864\n",
            "Iteration 59, loss = 0.44221888\n",
            "Iteration 60, loss = 0.44007383\n",
            "Iteration 61, loss = 0.43353416\n",
            "Iteration 62, loss = 0.43347450\n",
            "Iteration 63, loss = 0.42680072\n",
            "Iteration 64, loss = 0.43204847\n",
            "Iteration 65, loss = 0.42218551\n",
            "Iteration 66, loss = 0.41557280\n",
            "Iteration 67, loss = 0.41512960\n",
            "Iteration 68, loss = 0.41339845\n",
            "Iteration 69, loss = 0.41696147\n",
            "Iteration 70, loss = 0.40959573\n",
            "Iteration 71, loss = 0.40405632\n",
            "Iteration 72, loss = 0.40649277\n",
            "Iteration 73, loss = 0.40359648\n",
            "Iteration 74, loss = 0.39985496\n",
            "Iteration 75, loss = 0.40006662\n",
            "Iteration 76, loss = 0.39455316\n",
            "Iteration 77, loss = 0.38987133\n",
            "Iteration 78, loss = 0.38174524\n",
            "Iteration 79, loss = 0.38575228\n",
            "Iteration 80, loss = 0.38079919\n",
            "Iteration 81, loss = 0.37946616\n",
            "Iteration 82, loss = 0.37886234\n",
            "Iteration 83, loss = 0.37461496\n",
            "Iteration 84, loss = 0.37225080\n",
            "Iteration 85, loss = 0.36331903\n",
            "Iteration 86, loss = 0.36816622\n",
            "Iteration 87, loss = 0.36890497\n",
            "Iteration 88, loss = 0.36003934\n",
            "Iteration 89, loss = 0.35333229\n",
            "Iteration 90, loss = 0.35329857\n",
            "Iteration 91, loss = 0.35027226\n",
            "Iteration 92, loss = 0.35271529\n",
            "Iteration 93, loss = 0.34216001\n",
            "Iteration 94, loss = 0.34177264\n",
            "Iteration 95, loss = 0.33576252\n",
            "Iteration 96, loss = 0.33764123\n",
            "Iteration 97, loss = 0.33373139\n",
            "Iteration 98, loss = 0.33148009\n",
            "Iteration 99, loss = 0.32505941\n",
            "Iteration 100, loss = 0.32960639\n",
            "Iteration 101, loss = 0.32409140\n",
            "Iteration 102, loss = 0.31794112\n",
            "Iteration 103, loss = 0.31997168\n",
            "Iteration 104, loss = 0.32219391\n",
            "Iteration 105, loss = 0.31686573\n",
            "Iteration 106, loss = 0.31728440\n",
            "Iteration 107, loss = 0.30926180\n",
            "Iteration 108, loss = 0.30814449\n",
            "Iteration 109, loss = 0.30623721\n",
            "Iteration 110, loss = 0.29729712\n",
            "Iteration 111, loss = 0.29859945\n",
            "Iteration 112, loss = 0.28950118\n",
            "Iteration 113, loss = 0.29081070\n",
            "Iteration 114, loss = 0.29791317\n",
            "Iteration 115, loss = 0.29103093\n",
            "Iteration 116, loss = 0.29246991\n",
            "Iteration 117, loss = 0.28978851\n",
            "Iteration 118, loss = 0.28567371\n",
            "Iteration 119, loss = 0.27759534\n",
            "Iteration 120, loss = 0.28160329\n",
            "Iteration 121, loss = 0.27251603\n",
            "Iteration 122, loss = 0.27238637\n",
            "Iteration 123, loss = 0.26636377\n",
            "Iteration 124, loss = 0.26475439\n",
            "Iteration 125, loss = 0.27038885\n",
            "Iteration 126, loss = 0.27037440\n",
            "Iteration 127, loss = 0.26799564\n",
            "Iteration 128, loss = 0.25885118\n",
            "Iteration 129, loss = 0.26069923\n",
            "Iteration 130, loss = 0.25719857\n",
            "Iteration 131, loss = 0.25638919\n",
            "Iteration 132, loss = 0.25113449\n",
            "Iteration 133, loss = 0.25221399\n",
            "Iteration 134, loss = 0.24584926\n",
            "Iteration 135, loss = 0.24560104\n",
            "Iteration 136, loss = 0.24501103\n",
            "Iteration 137, loss = 0.23717331\n",
            "Iteration 138, loss = 0.23066079\n",
            "Iteration 139, loss = 0.23636851\n",
            "Iteration 140, loss = 0.25313443\n",
            "Iteration 141, loss = 0.24587574\n",
            "Iteration 142, loss = 0.23166945\n",
            "Iteration 143, loss = 0.22416049\n",
            "Iteration 144, loss = 0.22603987\n",
            "Iteration 145, loss = 0.22754184\n",
            "Iteration 146, loss = 0.22000431\n",
            "Iteration 147, loss = 0.21583772\n",
            "Iteration 148, loss = 0.21777283\n",
            "Iteration 149, loss = 0.21232787\n",
            "Iteration 150, loss = 0.21403409\n",
            "Iteration 151, loss = 0.22263610\n",
            "Iteration 152, loss = 0.20732971\n",
            "Iteration 153, loss = 0.20306062\n",
            "Iteration 154, loss = 0.20305094\n",
            "Iteration 155, loss = 0.20167311\n",
            "Iteration 156, loss = 0.21177070\n",
            "Iteration 157, loss = 0.19934523\n",
            "Iteration 158, loss = 0.20296118\n",
            "Iteration 159, loss = 0.19230670\n",
            "Iteration 160, loss = 0.19338708\n",
            "Iteration 161, loss = 0.19645936\n",
            "Iteration 162, loss = 0.19906574\n",
            "Iteration 163, loss = 0.19347706\n",
            "Iteration 164, loss = 0.18339172\n",
            "Iteration 165, loss = 0.18402510\n",
            "Iteration 166, loss = 0.18404215\n",
            "Iteration 167, loss = 0.18194664\n",
            "Iteration 168, loss = 0.18013705\n",
            "Iteration 169, loss = 0.17914733\n",
            "Iteration 170, loss = 0.17497460\n",
            "Iteration 171, loss = 0.18361548\n",
            "Iteration 172, loss = 0.17637822\n",
            "Iteration 173, loss = 0.16736054\n",
            "Iteration 174, loss = 0.17096861\n",
            "Iteration 175, loss = 0.16582104\n",
            "Iteration 176, loss = 0.16618710\n",
            "Iteration 177, loss = 0.16595916\n",
            "Iteration 178, loss = 0.16986481\n",
            "Iteration 179, loss = 0.17366747\n",
            "Iteration 180, loss = 0.16487812\n",
            "Iteration 181, loss = 0.15936694\n",
            "Iteration 182, loss = 0.16010419\n",
            "Iteration 183, loss = 0.15622027\n",
            "Iteration 184, loss = 0.15371471\n",
            "Iteration 185, loss = 0.15088008\n",
            "Iteration 186, loss = 0.15377480\n",
            "Iteration 187, loss = 0.15110493\n",
            "Iteration 188, loss = 0.15509045\n",
            "Iteration 189, loss = 0.15450521\n",
            "Iteration 190, loss = 0.14655437\n",
            "Iteration 191, loss = 0.14320512\n",
            "Iteration 192, loss = 0.13477749\n",
            "Iteration 193, loss = 0.13262757\n",
            "Iteration 194, loss = 0.14078931\n",
            "Iteration 195, loss = 0.13601031\n",
            "Iteration 196, loss = 0.14198252\n",
            "Iteration 197, loss = 0.13114775\n",
            "Iteration 198, loss = 0.14431461\n",
            "Iteration 199, loss = 0.14269959\n",
            "Iteration 200, loss = 0.13731185\n",
            "Iteration 201, loss = 0.14136039\n",
            "Iteration 202, loss = 0.13287524\n",
            "Iteration 203, loss = 0.14148833\n",
            "Iteration 204, loss = 0.14752668\n",
            "Iteration 205, loss = 0.14647181\n",
            "Iteration 206, loss = 0.13357990\n",
            "Iteration 207, loss = 0.12758719\n",
            "Iteration 208, loss = 0.11720063\n",
            "Iteration 209, loss = 0.11707677\n",
            "Iteration 210, loss = 0.13336033\n",
            "Iteration 211, loss = 0.15410187\n",
            "Iteration 212, loss = 0.12499364\n",
            "Iteration 213, loss = 0.12168973\n",
            "Iteration 214, loss = 0.11288187\n",
            "Iteration 215, loss = 0.10639135\n",
            "Iteration 216, loss = 0.10803073\n",
            "Iteration 217, loss = 0.10835416\n",
            "Iteration 218, loss = 0.13080230\n",
            "Iteration 219, loss = 0.12813848\n",
            "Iteration 220, loss = 0.12850718\n",
            "Iteration 221, loss = 0.11040013\n",
            "Iteration 222, loss = 0.09912860\n",
            "Iteration 223, loss = 0.10078189\n",
            "Iteration 224, loss = 0.10418656\n",
            "Iteration 225, loss = 0.11736285\n",
            "Iteration 226, loss = 0.12223754\n",
            "Iteration 227, loss = 0.10401862\n",
            "Iteration 228, loss = 0.09479085\n",
            "Iteration 229, loss = 0.09444443\n",
            "Iteration 230, loss = 0.09712627\n",
            "Iteration 231, loss = 0.09147356\n",
            "Iteration 232, loss = 0.09678954\n",
            "Iteration 233, loss = 0.09033877\n",
            "Iteration 234, loss = 0.08855785\n",
            "Iteration 235, loss = 0.09163337\n",
            "Iteration 236, loss = 0.09655316\n",
            "Iteration 237, loss = 0.09123140\n",
            "Iteration 238, loss = 0.09209613\n",
            "Iteration 239, loss = 0.09869390\n",
            "Iteration 240, loss = 0.09193891\n",
            "Iteration 241, loss = 0.07956472\n",
            "Iteration 242, loss = 0.08642735\n",
            "Iteration 243, loss = 0.09943902\n",
            "Iteration 244, loss = 0.10981202\n",
            "Iteration 245, loss = 0.09709297\n",
            "Iteration 246, loss = 0.08115802\n",
            "Iteration 247, loss = 0.08064404\n",
            "Iteration 248, loss = 0.08696603\n",
            "Iteration 249, loss = 0.08544754\n",
            "Iteration 250, loss = 0.08005342\n",
            "Iteration 251, loss = 0.08133013\n",
            "Iteration 252, loss = 0.09185735\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "\n",
            "‚úì Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìà Evaluating model performance...\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = mlp_clf.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"üéØ MODEL ACCURACY: {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPJex6khtE-a",
        "outputId": "25a2b7f3-f273-48d9-c805-fd0e3ae5ec1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìà Evaluating model performance...\n",
            "\n",
            "==================================================\n",
            "üéØ MODEL ACCURACY: 69.20%\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "year=[1950,1960,1970,2000]\n",
        "pop=[2.2324, 3.654, 4.655,5.768]\n",
        "plt.plot(year,pop)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "a5txqxA7HdTm",
        "outputId": "0cf3175f-185e-4692-a289-b37de7358cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(plt.hist)"
      ],
      "metadata": {
        "id": "RZcNo6VmuKuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88eedd6b-9df4-466c-accf-6df04f6af132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function hist in module matplotlib.pyplot:\n",
            "\n",
            "hist(x: 'ArrayLike | Sequence[ArrayLike]', bins: 'int | Sequence[float] | str | None' = None, *, range: 'tuple[float, float] | None' = None, density: 'bool' = False, weights: 'ArrayLike | None' = None, cumulative: 'bool | float' = False, bottom: 'ArrayLike | float | None' = None, histtype: \"Literal['bar', 'barstacked', 'step', 'stepfilled']\" = 'bar', align: \"Literal['left', 'mid', 'right']\" = 'mid', orientation: \"Literal['vertical', 'horizontal']\" = 'vertical', rwidth: 'float | None' = None, log: 'bool' = False, color: 'ColorType | Sequence[ColorType] | None' = None, label: 'str | Sequence[str] | None' = None, stacked: 'bool' = False, data=None, **kwargs) -> 'tuple[np.ndarray | list[np.ndarray], np.ndarray, BarContainer | Polygon | list[BarContainer | Polygon]]'\n",
            "    Compute and plot a histogram.\n",
            "\n",
            "    This method uses `numpy.histogram` to bin the data in *x* and count the\n",
            "    number of values in each bin, then draws the distribution either as a\n",
            "    `.BarContainer` or `.Polygon`. The *bins*, *range*, *density*, and\n",
            "    *weights* parameters are forwarded to `numpy.histogram`.\n",
            "\n",
            "    If the data has already been binned and counted, use `~.bar` or\n",
            "    `~.stairs` to plot the distribution::\n",
            "\n",
            "        counts, bins = np.histogram(x)\n",
            "        plt.stairs(counts, bins)\n",
            "\n",
            "    Alternatively, plot pre-computed bins and counts using ``hist()`` by\n",
            "    treating each bin as a single point with a weight equal to its count::\n",
            "\n",
            "        plt.hist(bins[:-1], bins, weights=counts)\n",
            "\n",
            "    The data input *x* can be a singular array, a list of datasets of\n",
            "    potentially different lengths ([*x0*, *x1*, ...]), or a 2D ndarray in\n",
            "    which each column is a dataset. Note that the ndarray form is\n",
            "    transposed relative to the list form. If the input is an array, then\n",
            "    the return value is a tuple (*n*, *bins*, *patches*); if the input is a\n",
            "    sequence of arrays, then the return value is a tuple\n",
            "    ([*n0*, *n1*, ...], *bins*, [*patches0*, *patches1*, ...]).\n",
            "\n",
            "    Masked arrays are not supported.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    x : (n,) array or sequence of (n,) arrays\n",
            "        Input values, this takes either a single array or a sequence of\n",
            "        arrays which are not required to be of the same length.\n",
            "\n",
            "    bins : int or sequence or str, default: :rc:`hist.bins`\n",
            "        If *bins* is an integer, it defines the number of equal-width bins\n",
            "        in the range.\n",
            "\n",
            "        If *bins* is a sequence, it defines the bin edges, including the\n",
            "        left edge of the first bin and the right edge of the last bin;\n",
            "        in this case, bins may be unequally spaced.  All but the last\n",
            "        (righthand-most) bin is half-open.  In other words, if *bins* is::\n",
            "\n",
            "            [1, 2, 3, 4]\n",
            "\n",
            "        then the first bin is ``[1, 2)`` (including 1, but excluding 2) and\n",
            "        the second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n",
            "        *includes* 4.\n",
            "\n",
            "        If *bins* is a string, it is one of the binning strategies\n",
            "        supported by `numpy.histogram_bin_edges`: 'auto', 'fd', 'doane',\n",
            "        'scott', 'stone', 'rice', 'sturges', or 'sqrt'.\n",
            "\n",
            "    range : tuple or None, default: None\n",
            "        The lower and upper range of the bins. Lower and upper outliers\n",
            "        are ignored. If not provided, *range* is ``(x.min(), x.max())``.\n",
            "        Range has no effect if *bins* is a sequence.\n",
            "\n",
            "        If *bins* is a sequence or *range* is specified, autoscaling\n",
            "        is based on the specified bin range instead of the\n",
            "        range of x.\n",
            "\n",
            "    density : bool, default: False\n",
            "        If ``True``, draw and return a probability density: each bin\n",
            "        will display the bin's raw count divided by the total number of\n",
            "        counts *and the bin width*\n",
            "        (``density = counts / (sum(counts) * np.diff(bins))``),\n",
            "        so that the area under the histogram integrates to 1\n",
            "        (``np.sum(density * np.diff(bins)) == 1``).\n",
            "\n",
            "        If *stacked* is also ``True``, the sum of the histograms is\n",
            "        normalized to 1.\n",
            "\n",
            "    weights : (n,) array-like or None, default: None\n",
            "        An array of weights, of the same shape as *x*.  Each value in\n",
            "        *x* only contributes its associated weight towards the bin count\n",
            "        (instead of 1).  If *density* is ``True``, the weights are\n",
            "        normalized, so that the integral of the density over the range\n",
            "        remains 1.\n",
            "\n",
            "    cumulative : bool or -1, default: False\n",
            "        If ``True``, then a histogram is computed where each bin gives the\n",
            "        counts in that bin plus all bins for smaller values. The last bin\n",
            "        gives the total number of datapoints.\n",
            "\n",
            "        If *density* is also ``True`` then the histogram is normalized such\n",
            "        that the last bin equals 1.\n",
            "\n",
            "        If *cumulative* is a number less than 0 (e.g., -1), the direction\n",
            "        of accumulation is reversed.  In this case, if *density* is also\n",
            "        ``True``, then the histogram is normalized such that the first bin\n",
            "        equals 1.\n",
            "\n",
            "    bottom : array-like, scalar, or None, default: None\n",
            "        Location of the bottom of each bin, i.e. bins are drawn from\n",
            "        ``bottom`` to ``bottom + hist(x, bins)`` If a scalar, the bottom\n",
            "        of each bin is shifted by the same amount. If an array, each bin\n",
            "        is shifted independently and the length of bottom must match the\n",
            "        number of bins. If None, defaults to 0.\n",
            "\n",
            "    histtype : {'bar', 'barstacked', 'step', 'stepfilled'}, default: 'bar'\n",
            "        The type of histogram to draw.\n",
            "\n",
            "        - 'bar' is a traditional bar-type histogram.  If multiple data\n",
            "          are given the bars are arranged side by side.\n",
            "        - 'barstacked' is a bar-type histogram where multiple\n",
            "          data are stacked on top of each other.\n",
            "        - 'step' generates a lineplot that is by default unfilled.\n",
            "        - 'stepfilled' generates a lineplot that is by default filled.\n",
            "\n",
            "    align : {'left', 'mid', 'right'}, default: 'mid'\n",
            "        The horizontal alignment of the histogram bars.\n",
            "\n",
            "        - 'left': bars are centered on the left bin edges.\n",
            "        - 'mid': bars are centered between the bin edges.\n",
            "        - 'right': bars are centered on the right bin edges.\n",
            "\n",
            "    orientation : {'vertical', 'horizontal'}, default: 'vertical'\n",
            "        If 'horizontal', `~.Axes.barh` will be used for bar-type histograms\n",
            "        and the *bottom* kwarg will be the left edges.\n",
            "\n",
            "    rwidth : float or None, default: None\n",
            "        The relative width of the bars as a fraction of the bin width.  If\n",
            "        ``None``, automatically compute the width.\n",
            "\n",
            "        Ignored if *histtype* is 'step' or 'stepfilled'.\n",
            "\n",
            "    log : bool, default: False\n",
            "        If ``True``, the histogram axis will be set to a log scale.\n",
            "\n",
            "    color : :mpltype:`color` or list of :mpltype:`color` or None, default: None\n",
            "        Color or sequence of colors, one per dataset.  Default (``None``)\n",
            "        uses the standard line color sequence.\n",
            "\n",
            "    label : str or list of str, optional\n",
            "        String, or sequence of strings to match multiple datasets.  Bar\n",
            "        charts yield multiple patches per dataset, but only the first gets\n",
            "        the label, so that `~.Axes.legend` will work as expected.\n",
            "\n",
            "    stacked : bool, default: False\n",
            "        If ``True``, multiple data are stacked on top of each other If\n",
            "        ``False`` multiple data are arranged side by side if histtype is\n",
            "        'bar' or on top of each other if histtype is 'step'\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    n : array or list of arrays\n",
            "        The values of the histogram bins. See *density* and *weights* for a\n",
            "        description of the possible semantics.  If input *x* is an array,\n",
            "        then this is an array of length *nbins*. If input is a sequence of\n",
            "        arrays ``[data1, data2, ...]``, then this is a list of arrays with\n",
            "        the values of the histograms for each of the arrays in the same\n",
            "        order.  The dtype of the array *n* (or of its element arrays) will\n",
            "        always be float even if no weighting or normalization is used.\n",
            "\n",
            "    bins : array\n",
            "        The edges of the bins. Length nbins + 1 (nbins left edges and right\n",
            "        edge of last bin).  Always a single array even when multiple data\n",
            "        sets are passed in.\n",
            "\n",
            "    patches : `.BarContainer` or list of a single `.Polygon` or list of such objects\n",
            "        Container of individual artists used to create the histogram\n",
            "        or list of such containers if there are multiple input datasets.\n",
            "\n",
            "    Other Parameters\n",
            "    ----------------\n",
            "    data : indexable object, optional\n",
            "        If given, the following parameters also accept a string ``s``, which is\n",
            "        interpreted as ``data[s]`` if ``s`` is a key in ``data``:\n",
            "\n",
            "        *x*, *weights*\n",
            "\n",
            "    **kwargs\n",
            "        `~matplotlib.patches.Patch` properties. The following properties\n",
            "        additionally accept a sequence of values corresponding to the\n",
            "        datasets in *x*:\n",
            "        *edgecolor*, *facecolor*, *linewidth*, *linestyle*, *hatch*.\n",
            "\n",
            "        .. versionadded:: 3.10\n",
            "           Allowing sequences of values in above listed Patch properties.\n",
            "\n",
            "    See Also\n",
            "    --------\n",
            "    hist2d : 2D histogram with rectangular bins\n",
            "    hexbin : 2D histogram with hexagonal bins\n",
            "    stairs : Plot a pre-computed histogram\n",
            "    bar : Plot a pre-computed histogram\n",
            "\n",
            "    Notes\n",
            "    -----\n",
            "\n",
            "    .. note::\n",
            "\n",
            "        This is the :ref:`pyplot wrapper <pyplot_interface>` for `.axes.Axes.hist`.\n",
            "\n",
            "    For large numbers of bins (>1000), plotting can be significantly\n",
            "    accelerated by using `~.Axes.stairs` to plot a pre-computed histogram\n",
            "    (``plt.stairs(*np.histogram(data))``), or by setting *histtype* to\n",
            "    'step' or 'stepfilled' rather than 'bar' or 'barstacked'.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}